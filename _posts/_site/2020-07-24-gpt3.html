<p>What does it mean to have freedom of speech? Naively, it means that you have
the right to express ideas without fear of
governmental retaliation or censorship. But that’s not worth much in a vacuum.
Free speech is valuable when you are communicating with others: abstractly,
freedom of speech means the right to distribute information to an audience.</p>

<p>If you frame freedom of speech not in terms of what comes out of your mouth,
but in terms of the interaction between yourself and another party,<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> then edge cases
rapidly emerge. For example, suppose that you are on the street,
lawfully raising a protest sign supporting X.
You are hoping to persuade passers-by. The government
sends in <em>five hundred</em> counter-protestors, peacefully raising <em>not X</em> signs. Your
voice is drowned out in the crowd. You are unable to reach the passers-by; it’s
as if you were not there. Is this censorship? I am no constitutional lawyer,
but the effect is undeniably censorious – it is practically as if you had
been sent home by the police.</p>

<p>Historically, I haven’t seen this type of scenario give rise to much
concern among constitutional scholars – perhaps for reasons of practicality.
Perpetually mobilizing the <a href="https://en.wikipedia.org/wiki/Astroturfing">astroturf</a>
brigades to drown out individual voices is hardly practically feasible.</p>

<p>However, this has dangerously changed as discourse has moved online.
The real-world constraints to astroturfing do not exist online.
With <a href="https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/">GPT-3</a>,
the marginal cost of distributing astroturfed propaganda online has firmly hit zero.
GPT-3 represents the newest generation of text-generating AI, and it is extremely
good – perfectly indistinguishable from a human in short form, articulate,
detailed, and capable of infinite variety
in style and tone.
Now it is actually possible for any online group discussion to be brigaded by
thousands of automated users – indistinguishable from real humans –
twisting the conversation, while drowning out the voices of real humans.</p>

<p>This will become common in no time.
It’s too effective a weapon for malicious states to pass it up.
Manual online astroturfing
is already widespread. Both <a href="https://en.wikipedia.org/wiki/Internet_Water_Army">China</a>
and <a href="https://en.wikipedia.org/wiki/Internet_Research_Agency">Russia</a>
pay thousands of state employees to spread propaganda online.
As
<a href="https://en.wikipedia.org/wiki/Russian_interference_in_the_2016_United_States_elections">Russiagate</a>
and the now widespread conspiracy theories on Antivax, 5G, COVID-19, etc.
show, it’s very effective: social media platforms
have enabled divide-and-conquer strategies at unprecedented scale and granularity.
They have become a battleground for the opinions of people in the West,
and these people haven’t realized it yet.
Using fully automated, infinitely scalable tools to
infect the minds of your opponents with malicious ideas and sow discord
offers an unprecedentedly high ROI to the villains of the world.</p>

<p>Thus, we are moving into a world where bad actors can interfere with free
speech with a new form of censorship: the use of automated voices, indistinguishable
from real ones, to overpower genuine voices online, and to shape the appearance
of public discourse according to their goals. If you believe, as many scholars do,
that democratic
societies are critically reliant on your freedom to distribute information,
then this poses a severe threat.</p>

<p>The abstract problem is that on the internet, we don’t have a good way
to tell real humans from fake ones.
The current state-of-the-art tests
are CAPTCHAs with challenges that “only humans could pass”:
read the word,
click all the squares with traffic lights, and so forth.
Obviously these aren’t
going to resist automation for long.
They will be useless across the board in a few years, once general image recognition
tools are as good as some substantial minority of humans.</p>

<p>In the long term,
AI will be effectively impossible to distinguish from humans
online.
The only
solution is to use what we have and they don’t – real-world identification.
A real-world ID could correspond to some set of private keys,
so you could sign your online actions to prove
their human authenticity.
You could have a large number of private keys,
so as to enable ample pseudonymity.
However, true anonymity – not leveraging real-world identity in some sense –
becomes impossible<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup> without opening up the possibility of mass creation
of automated trolls.</p>

<p>In conclusion: free speech is not just about freedom from straight-forward censorship,
but about your ability to participate in discourse without
state interference. GPT-3 marks a new generation of tools enabling states
to interfere in online discourse with unprecedented scale and persuasiveness,
enabling great damage at low cost.
It is clear that on the internet, AI will become indistinguishable from
genuine humans in the next few years. To that extent, we have to protect
our freedom of speech. It seems like
requiring real-world IDs and coupling them with public key cryptography
is the only way out, which keeps pseudonymity but loses anonymity.</p>

<p>Losing anonymity to protect free speech is counter-intuitive and somewhat repulsive.
I believe in individual freedom as the highest ideal.
I used to think anonymity was one of the greatest values
provided by the internet. And I acknowledge that eliminating anonymity
to protect free speech comes with its own issues in the long run:
for example, a malicious government
could abuse the real-world-ID-to-private-key link to very effectively crack
down on free speech. I don’t <em>like</em> the solution I am advocating, but it’s a
difficult trade-off.</p>

<p><br /></p>

<hr />

<div class="footnotes">
  <ol>
    <li id="fn:1">

      <p>This is a common framing among constitutional scholars, for example
in the writings of <a href="https://en.wikipedia.org/wiki/Alexander_Meiklejohn">Alexander Meiklejohn</a>. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">

      <p>Clever leveraging of blockchain-style cryptographic protocols might actually
make it possible, at least in theory.
I am reminded of Monero’s <a href="https://en.wikipedia.org/wiki/Ring_signature">Ring Signatures</a>
or ZCash’s <a href="https://en.wikipedia.org/wiki/Non-interactive_zero-knowledge_proof">Non-Interactive Zero-Knowledge Proofs</a>.
It’s possible that even if every real-world identity were linked to some
set of private keys, a user’s action could be computed in such a way to not reveal their identity;
similar how Monero and ZCash do not reveal identities of parties in a transaction.
For this theory to become reality, effectively the entire internet would have to run
on a blockchain,
which would be interesting.
I’ll try to explore the viability of this approach
in a future post. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
