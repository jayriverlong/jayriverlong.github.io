---
layout: post
title: Two Paradigms of Personal Computing
date:   2020-10-27
summary: There exist two very different classes of personal computing.
    Some machines are made to extend the self, others are made to merge with the self.
---


A frequently recurring staple of Hacker News is the *personal computing rant*:
modern computers are black boxes, far too locked down.[^1]
We long for our desktop computers, the early-2000s computing paradigm,
and we want to take back control of our data.


I sympathize greatly with this view.
For the past five years, I have exclusively run Arch Linux.
I love the early-2000s style of personal computing: text-heavy interfaces,
words rather than icons, uniform keyboard shortcuts everywhere.
I do nearly all my computing in emacs.
It is feature rich, and no product manager is ever going to change the experience, interface, or shortcuts.
My workspace allows me to be *fast*.
Contrary to much modern software, emacs responds instantaneously to my keystrokes.
Every action has an immediate effect, clear on the page, with no background process ambiguity.
This is enormously satisfying.
I would characterize this computing environment as a
spiritual descendant of the typewriter:
on its own, it is a dumb machine, but when you command it, it becomes a powerful
extension of you.
The user experience is given by speed, smoothness, reliability, and nothing else.


On the other hand, you've got iPhones and iPads.
These are not machines that you command -- on the contrary, you might argue
that all their notifications command you. With touch interfaces,
facial recognition, and
voice control, these are machines that are meant to merge with you.
Instead of becoming an *extension* of you, it becomes *part* of you.
Instead of you commanding it, it is meant to anticipate your commands.
Where is the data? How does it work? Who knows. They're total black boxes,
effectively indistinguishable from magic, whereas your Linux Desktop is a
DIYable simple machine.[^2]


Many contemporary writers think of personal computing as
one paradigm that is gradually evolving. I disagree: I think there are two,
deeply different paradigms of personal computing, reflecting deeply different desires.

- Machine as extension of the self (your Windows XP Desktop).
- Machine as part of the self (your iPhone).


Plenty of devices exist in the space in-between. Android phones
try to give you some control back over your device, by which they necessarily
preclude themselves from truly being *part* of you. Modern versions of OS X,
with the touchbar, Siri, and integrations into all your other Apple devices, are
starting to make the leap from extending the self to being part of the self.


As a genre, the personal computing rant comes out of the correct view that
these are all forms of personal computing, but it fails to recognize that
within this broad umbrella, we've seen paradigms arise that differ in both
intent and the human desire they're meant to meet.
It's not that one
class of devices is replacing the other.
They are fundamentally different, and one paradigm succeeds where the other
falls short of meeting the consumers' needs.
The terminal never met the needs of those who want Amazon Alexa, and vice-versa.


I live in the in-between. I happily imagine a world where my Apple Watch
monitors my glucose and blood oxygen, my Eight Sleep quantifies my rest,
I mark up documents on giant touchscreens, but I sit on a clacky
IBM keyboard to write code and blog posts in a terminal that hasn't changed
in twenty years. While your iPhone might meld with your mind by quantifying
and anticipating your every need, my terminal melds with my mind by
being fast, constant, and *always* correct. Each has its place, and I would
never trade one for the other.




<br/>

---


[^1]: This essay was inspired by a recent hit on Hacker News,
    in which the [Author is Seriously Considering Going Back to Desktop Computers](http://misc-stuff.terraaeon.com/articles/locked-down-computers.html).

[^2]: To me, a Linux desktop is almost more like a typewriter than it is like an iPhone.
    I can peek inside and understand how most of the tech works.
    I can debug it, swap out components, and so on.
    It's like a mechanism of levers and cogs: complicated, perhaps, but understandable
    and possible to reason deeply about. An iPhone is inaccessible in all these
    respects; it might as well be a magic wand. That's not necessarily a bad thing,
    these are just very different classes of object.
